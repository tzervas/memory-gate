# Default values for memory-gate chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1 # Default to 1, can be overridden by HPA or manually

image:
  repository: your-repo/memory-gate # TODO: Replace with your actual image repository
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podSecurityContext:
  fsGroup: 1000 # Corresponds to appuser in Dockerfile
  runAsUser: 1000
  runAsGroup: 1000

securityContext:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false # Set to true if possible, but may require app changes
  runAsNonRoot: true
  # runAsUser: 1001 # Should match Dockerfile user if not using fsGroup approach

service:
  type: ClusterIP
  port: 8000 # Port the service will expose
  targetPort: 8000 # Port the application pod listens on

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: memory-gate.local # TODO: change this to your desired host
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: memory-gate-tls
  #    hosts:
  #      - memory-gate.local

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 1000m # 1 CPU core
    memory: 2Gi # 2 Gigabytes
    # nvidia.com/gpu: 1 # Uncomment if GPUs are needed and node has them
  requests:
    cpu: 250m # 0.25 CPU core
    memory: 512Mi # 0.5 Gigabyte
    # nvidia.com/gpu: 1 # Uncomment if GPUs are needed

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  # targetMemoryUtilizationPercentage: 75 # Requires metrics-server with memory metrics

# Persistence for ChromaDB data
persistence:
  enabled: true
  storageClass: "" # Optional: specify storage class, e.g., "fast-ssd", "standard"
  accessMode: ReadWriteOnce
  size: 20Gi # Default size for ChromaDB data
  mountPath: /app/data/chromadb_store # Path where ChromaDB data is stored inside the container

# Application specific configuration
application:
  logLevel: INFO
  # ChromaDB settings (if configured via app, not a separate ChromaDB instance)
  chroma:
    persistDirectory: /app/data/chromadb_store # Must match persistence.mountPath
    collectionName: "memory_gate_prod_collection"
  # Consolidation worker settings
  consolidation:
    enabled: true
    intervalSeconds: 3600 # 1 hour

# External services (if used)
# Example: Redis for caching or as a message broker (if MemoryGate were to use it)
# redis:
#   enabled: false # Set to true to deploy Redis from Bitnami chart (requires adding dependency to Chart.yaml)
#   auth:
#     password: "your-redis-password" # TODO: Change or use secret

nodeSelector: {}
tolerations: []
affinity: {}

# Extra environment variables to be passed to the application pods
extraEnv:
  # PYTHONUNBUFFERED: "1" # Already set in Dockerfile, but can be overridden
  # UV_SYSTEM_PYTHON: "true" # If needed by uv in production
  # Example:
  # ANOTHER_CONFIG: "value"
  # S3_BUCKET_NAME: "my-memory-archive-bucket" # If using S3 for archival

# Prometheus ServiceMonitor configuration
serviceMonitor:
  enabled: false
  namespace: "" # If empty, uses release namespace
  interval: 30s
  scrapeTimeout: 10s
  labels: {} # Additional labels for the ServiceMonitor
  # path: /metrics # Assuming your app exposes metrics at /metrics
  # targetPort: 8000 # Port name or number from the service
  # scheme: http
  # tlsConfig: {} # If metrics endpoint uses TLS

# Grafana dashboard configuration (placeholder, actual dashboard JSON would be separate)
grafanaDashboard:
  enabled: false
  namespace: "" # If empty, uses release namespace
  # configMapName: "" # Name of ConfigMap containing dashboard JSON
  # labels: {} # Additional labels for the GrafanaDashboard resource

# Distributed Tracing (e.g., OpenTelemetry)
tracing:
  enabled: false
  # OTLP_ENDPOINT: "http://otel-collector.observability:4317" # Example OTLP endpoint
  # SERVICE_NAME: "memory-gate"
  # SAMPLING_RATIO: "0.1" # Sample 10% of traces
